{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n=100\n",
    "#number of samples per class: n\n",
    "k=2\n",
    "#number of classes: k\n",
    "d=2\n",
    "#dimensionality of samples: d\n",
    "mus=np.random.random((k,d))*20-10 \n",
    "#mean of the multivariate normal distribution | mus[i,j] is the mean for the ith cluster at the jth dimension\n",
    "# sigma=[np.eye(d) for i in range(k)]\n",
    "#standard deviations are all assumed to be one. As the covariance matrix is identity the dimensions can be sampled independently\n",
    "# Pc=np.ones(k)/k\n",
    "#setting priors: Pc\n",
    "\n",
    "#Data Generation\n",
    "X=[]\n",
    "for i in range(n):\n",
    "    for j in range(k):\n",
    "#for each class generate n tuples of size d, taken from the distribution N(mus[j],1)\n",
    "        point=[mean+np.random.randn() for mean in mus[j]]\n",
    "        X.append(point)\n",
    "#we have our dataset, where each point is a d+1 dimensional tuple where the last position represents its class \n",
    "\n",
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_mat(i,j):\n",
    "\n",
    "    # A nxd matrix holding whose elements are tuples of the type (i,j)\n",
    "    # this matrix acts as pointer to respective to elements in  X, new_mus,new_cov\n",
    "\n",
    "    # a = multivariate_normal.pdf(\\\n",
    "    #         X[index_matrix[i][j][0]],\\\n",
    "    #         mean=new_mus[index_matrix[i][j][1]],\\\n",
    "    #         cov=new_cov[index_matrix[i][j][1]],\\\n",
    "    #         allow_singular=True\\\n",
    "    #     )\n",
    "    # b = new_priors[index_matrix[i][j][1]]\n",
    "\n",
    "    a = multivariate_normal.pdf(X[i],mean=new_mus[j],cov=new_cov[j],allow_singular=True)\n",
    "    b = new_priors[j]\n",
    "    # print(i,j,a*b)\n",
    "    return a*b\n",
    "\n",
    "def tabulate(x, y, f):\n",
    "   \"\"\"Return a table of f(x, y).\"\"\"\n",
    "   #* is to unpack the two arrays which results after meshing\n",
    "   return np.vectorize(f)(* np.meshgrid(x, y))\n",
    "\n",
    "\n",
    "def cov_loop(n,m):\n",
    "    cov_var = np.zeros((X.shape[1],X.shape[1]),dtype=float)\n",
    "    for j in range(n):\n",
    "        cov_var += (W[m][j]/sum_w[m]) * (((X[j] - new_mus[m]).T) @ (X[j] - new_mus[m]))\n",
    "    return cov_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original [[-8.25453067 -0.83934678]\n",
      " [ 2.58580405  3.80500123]]\n",
      "initial [[ 8.65497865  9.96211716]\n",
      " [-3.75478124  1.73118803]]\n",
      "final 4 200 2 2 [[ 2.68373966  3.80735947]\n",
      " [-8.12263715 -0.83833731]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#dimension of the dataset\n",
    "d = X.shape[1]\n",
    "\n",
    "#number of points in the dataset\n",
    "n = X.shape[0]\n",
    "\n",
    "# index_matrix = np.empty((n,k),dtype=(int,2))\n",
    "# for ii in range(n):\n",
    "#     for jj in range(k):\n",
    "#         index_matrix[ii][jj] = (ii,jj)\n",
    "\n",
    "'''initialising means ---------------------------------'''\n",
    "# random means\n",
    "# old_mus = np.array([np.random.rand(d) for _ in range(k)])\n",
    "\n",
    "# select random datapoints from data as initial means\n",
    "# random_rows = np.random.choice(X.shape[0], size=k, replace=False)\n",
    "# old_mus = copy.deepcopy(X[random_rows, :])\n",
    "\n",
    "# choose means from unifrom random between 'a' and 'b' \n",
    "old_mus = np.random.random((k,d))*20-10 \n",
    "# old_mus = np.random.random((k,d))*np.max(X)-np.min(X)\n",
    "\n",
    "\n",
    "new_mus = copy.deepcopy(old_mus)\n",
    "print('original',mus)\n",
    "print(\"initial\", new_mus)\n",
    "'''-------------------------------------------------------'''\n",
    "\n",
    "\n",
    "'''initalising covariance matrices-------------------------'''\n",
    "#identity matrices of dxd dimension as covariance matrices\n",
    "old_cov = np.asarray([np.eye(d) for _ in range(k)])\n",
    "new_cov = copy.deepcopy(old_cov)\n",
    "'''-------------------------------------------------------'''\n",
    "\n",
    "'''initialising priors-------------------------------------'''\n",
    "#priors are 1/k where k is the number of classes\n",
    "old_priors = np.full((k),1/k)\n",
    "new_priors = copy.deepcopy(old_priors)\n",
    "'''-------------------------------------------------------'''\n",
    "\n",
    "#stopping condition\n",
    "eps = 1e-10\n",
    "\n",
    "#starting time\n",
    "t = 0\n",
    "\n",
    "#aritifcal condition to enter the loop\n",
    "obt_eps = 1\n",
    "\n",
    "t_data=[i[:d] for i in X]\n",
    "while (obt_eps > eps) or (t==0):\n",
    "    t += 1\n",
    "\n",
    "    '''Begin Expectation step---------------------------------------------------------'''\n",
    "    #get the W matrix\n",
    "    #unnormalised\n",
    "    W_temp = copy.deepcopy(tabulate(list(range(n)),list(range(k)),w_mat))\n",
    "    temp = copy.deepcopy(W_temp)\n",
    "    #normalised\n",
    "    W = copy.deepcopy(temp/temp.sum(axis=0))\n",
    "\n",
    "    if np.isfinite(W).all():\n",
    "        pass\n",
    "    else:\n",
    "        W_temp_where = np.where(temp.sum(axis=0)==0.0)\n",
    "        for ii in W_temp_where:\n",
    "            W[:,ii] = 1/k\n",
    "    '''End Expectation step------------------------------------------------------------'''\n",
    "\n",
    "    #get sum of W for each cluster\n",
    "    temp = copy.deepcopy(W)\n",
    "    sum_w = copy.deepcopy(temp.sum(axis=1))\n",
    "\n",
    "    denoms=[sum(W[i,:]) for i in range(k)]\n",
    "\n",
    "    '''Begin Maximization step---------------------------------------------------------'''\n",
    "    # re-estimate means\n",
    "    old_mus = copy.deepcopy(new_mus)\n",
    "    #unnormalised\n",
    "    new_mus_temp = copy.deepcopy(W @ X)\n",
    "    temp = copy.deepcopy(new_mus_temp)\n",
    "    #normalised\n",
    "    new_mus = copy.deepcopy(temp/sum_w[:,None])\n",
    "\n",
    "    # re-estimate covariance\n",
    "    old_cov = copy.deepcopy(new_cov)\n",
    "    #unnormalised\n",
    "    # new_cov_temp = copy.deepcopy([cov_loop(n,a) for a in range(k)])\n",
    "    # temp = copy.deepcopy(new_cov_temp)\n",
    "    #normalised\n",
    "    # new_cov = copy.deepcopy([temp[a]/sum_w[a] for a in range(k)])\n",
    "    new_cov = copy.deepcopy(new_cov)\n",
    "\n",
    "\n",
    "\n",
    "    # re-estimate priors\n",
    "    old_priors = copy.deepcopy(new_priors)\n",
    "    new_priors = copy.deepcopy(sum_w/n)\n",
    "    '''End Maximization step---------------------------------------------------------'''\n",
    "\n",
    "    obt_eps = np.sum([np.linalg.norm(new_mus[a]-old_mus[a]) for a in range(k)])\n",
    "print(\"final\", t,n,k,d,new_mus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Original means of the data for class 1 are: {} and the predicted means are {}'.format(mus[0],means[0]))\n",
    "# print('Original means of the data for class 2 are: {} and the predicted means are {}'.format(mus[1],means[1]))\n",
    "# print('The Original covariance matrix is an Identity matrix for both the classes.')\n",
    "# print('Predicted covariance matrices of the data for class 1 is: \\n {} \\n and for class 2 is \\n {}'.format(sigmas[0],sigmas[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\\s+ since dataset has one or more white spaces\n",
    "df = pd.read_csv(\"Dataset.data\",sep='\\s+',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7400 entries, 0 to 7399\n",
      "Data columns (total 21 columns):\n",
      "0     7400 non-null float64\n",
      "1     7400 non-null float64\n",
      "2     7400 non-null float64\n",
      "3     7400 non-null float64\n",
      "4     7400 non-null float64\n",
      "5     7400 non-null float64\n",
      "6     7400 non-null float64\n",
      "7     7400 non-null float64\n",
      "8     7400 non-null float64\n",
      "9     7400 non-null float64\n",
      "10    7400 non-null float64\n",
      "11    7400 non-null float64\n",
      "12    7400 non-null float64\n",
      "13    7400 non-null float64\n",
      "14    7400 non-null float64\n",
      "15    7400 non-null float64\n",
      "16    7400 non-null float64\n",
      "17    7400 non-null float64\n",
      "18    7400 non-null float64\n",
      "19    7400 non-null float64\n",
      "20    7400 non-null int64\n",
      "dtypes: float64(20), int64(1)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.to_numpy()\n",
    "X = X[:,:-1]\n",
    "\n",
    "mus = np.asarray(\n",
    "    [ [0]*X.shape[1],\n",
    "        [2/np.sqrt(20)]*X.shape[1]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original [[0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.4472136 0.4472136 0.4472136 0.4472136 0.4472136 0.4472136 0.4472136\n",
      "  0.4472136 0.4472136 0.4472136 0.4472136 0.4472136 0.4472136 0.4472136\n",
      "  0.4472136 0.4472136 0.4472136 0.4472136 0.4472136 0.4472136]]\n",
      "initial [[ 1.5616  1.3861 -1.4968  0.0423 -0.5552 -0.1046  0.7733 -0.3488 -0.6817\n",
      "   2.0427  0.2368 -0.4047  1.6686  1.8561  0.0464  1.3579  0.0431  0.7537\n",
      "   1.2374  0.9743]\n",
      " [ 1.2947  0.1998  1.8239 -0.8114  0.6682 -1.0951  1.2324  0.0799  1.4349\n",
      "  -1.266   0.5435  1.1515  0.2636  0.8395  1.5961  0.5107  0.702   2.0212\n",
      "  -0.574   0.1599]]\n",
      "final 28 [[-0.14980326 -0.09255678 -0.17987472 -0.10762475 -0.12251715 -0.12481045\n",
      "  -0.1372542  -0.09997686 -0.17708276 -0.10363845 -0.12277684 -0.1443822\n",
      "  -0.13757871 -0.16771707 -0.13804202 -0.14643852 -0.09917042 -0.16315795\n",
      "  -0.15543415 -0.1479515 ]\n",
      " [ 0.55643163  0.53327398  0.53438505  0.5335129   0.49029484  0.49069362\n",
      "   0.52678955  0.53263582  0.53575469  0.55092836  0.53333395  0.51187609\n",
      "   0.50678957  0.52225375  0.54846763  0.53110122  0.49866965  0.49507856\n",
      "   0.52912537  0.53540656]]\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "#dimension of the dataset\n",
    "d = X.shape[1]\n",
    "\n",
    "#number of points in the dataset\n",
    "n = X.shape[0]\n",
    "\n",
    "# index_matrix = np.empty((n,k),dtype=(int,2))\n",
    "# for ii in range(n):\n",
    "#     for jj in range(k):\n",
    "#         index_matrix[ii][jj] = (ii,jj)\n",
    "\n",
    "'''initialising means ---------------------------------'''\n",
    "# random means\n",
    "# old_mus = np.array([np.random.rand(d) for _ in range(k)])\n",
    "\n",
    "# select random datapoints from data as initial means\n",
    "random_rows = np.random.choice(X.shape[0], size=k, replace=False)\n",
    "old_mus = copy.deepcopy(X[random_rows, :])\n",
    "\n",
    "# choose means from unifrom random between 'a' and 'b' \n",
    "# old_mus = np.random.random((k,d))*20-10 \n",
    "# old_mus = np.random.random((k,d))*np.max(X)-np.min(X)\n",
    "\n",
    "\n",
    "new_mus = copy.deepcopy(old_mus)\n",
    "print('original',mus)\n",
    "print(\"initial\", new_mus)\n",
    "'''-------------------------------------------------------'''\n",
    "\n",
    "\n",
    "'''initalising covariance matrices-------------------------'''\n",
    "#identity matrices of dxd dimension as covariance matrices\n",
    "old_cov = np.asarray([np.eye(d) for _ in range(k)])\n",
    "new_cov = copy.deepcopy(old_cov)\n",
    "'''-------------------------------------------------------'''\n",
    "\n",
    "'''initialising priors-------------------------------------'''\n",
    "#priors are 1/k where k is the number of classes\n",
    "old_priors = np.full((k),1/k)\n",
    "new_priors = copy.deepcopy(old_priors)\n",
    "'''-------------------------------------------------------'''\n",
    "\n",
    "#stopping condition\n",
    "eps = 1e-10\n",
    "\n",
    "#starting time\n",
    "t = 0\n",
    "\n",
    "#aritifcal condition to enter the loop\n",
    "obt_eps = 1\n",
    "\n",
    "while (obt_eps > eps) or (t==0):\n",
    "    t += 1\n",
    "\n",
    "    '''Begin Expectation step---------------------------------------------------------'''\n",
    "    #get the W matrix\n",
    "    #unnormalised\n",
    "    W_temp = copy.deepcopy(tabulate(list(range(n)),list(range(k)),w_mat))\n",
    "    temp = copy.deepcopy(W_temp)\n",
    "    #normalised\n",
    "    W = copy.deepcopy(temp/temp.sum(axis=0))\n",
    "\n",
    "    # if np.isfinite(W).all():\n",
    "    #     pass\n",
    "    # else:\n",
    "    #     W_temp_where = np.where(temp.sum(axis=0)==0.0)\n",
    "    #     for ii in W_temp_where:\n",
    "    #         W[:,ii] = 1/k\n",
    "    '''End Expectation step------------------------------------------------------------'''\n",
    "\n",
    "    #get sum of W for each cluster\n",
    "    temp = copy.deepcopy(W)\n",
    "    sum_w = copy.deepcopy(temp.sum(axis=1))\n",
    "\n",
    "\n",
    "    '''Begin Maximization step---------------------------------------------------------'''\n",
    "    # re-estimate means\n",
    "    old_mus = copy.deepcopy(new_mus)\n",
    "    #unnormalised\n",
    "    new_mus_temp = copy.deepcopy(W @ X)\n",
    "    temp = copy.deepcopy(new_mus_temp)\n",
    "    #normalised\n",
    "    new_mus = copy.deepcopy(temp/sum_w[:,None])\n",
    "\n",
    "    # re-estimate covariance\n",
    "    old_cov = copy.deepcopy(new_cov)\n",
    "    #unnormalised\n",
    "    new_cov_temp = copy.deepcopy([cov_loop(n,a) for a in range(k)])\n",
    "    temp = copy.deepcopy(new_cov_temp)\n",
    "    #normalised\n",
    "    new_cov = copy.deepcopy([temp[a]/sum_w[a] for a in range(k)])\n",
    "\n",
    "\n",
    "    # re-estimate priors\n",
    "    old_priors = copy.deepcopy(new_priors)\n",
    "    new_priors = copy.deepcopy(sum_w/n)\n",
    "    '''End Maximization step---------------------------------------------------------'''\n",
    "\n",
    "    obt_eps = np.sum([np.linalg.norm(new_mus[a]-old_mus[a]) for a in range(k)])\n",
    "print(\"final\", t,new_mus)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f95d9307f45ddfb406dd09f6e4b2fa70e170c66451c4561bc8b2afdb5e53bc6a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
